1. 入门(092)
    anaconda3.5.3版本的安装和简介
    jupyter的使用
        shift + Enter : 从当前行向下顺序执行python指令
        Ctrl + Enter : 只执行当行python指令

2. 数据类型(093)
    type(变量或常量或有返回值的表达式) 函数: 查看数据类型的函数

    运算符 /  与 //  , 前者运算结束是完全除,即可得到实际结果, 后者是整除, 只获得整数结果值.

    运算符 % , 是求模运算, 即只获取两个操作数相除的余数

    单/双引号: 都表示字符串, 同时存在的意义是嵌套应用, 多外双内单.

    三引号: 当一个字符串中即有单引号, 又有双引号, 且有换行操作时, 可以使用此三引号

    转义符: \

    print() 函数输出字符串时, 不会输出字符串两端的引号的

3. 变量(094)
    批量初始化变量:  a,b,c = 1,2,3
    给变量赋空值: x = None
    数据的平方: a**2

4. 列表(095)
    list1=[1,2,3,4]
    列表求和: sum(list1)
    列表长度: len(list1)
    插入元素: list1.insert(位置, 值)
    添加元素: list1.append(值)
    添加多个元素: list1 = list1 + [5,6,7]
    弹出/删除元素: list1.pop(元素值), 不指定元素, 默认删除最后一个元素
    修改元素值: list1[索引]=新值

    索引列表元素: list1[0] , 默认列表的第一个元素的索引编号是 0
    列表切片: list1[0:2] , 从列表第一个元素到第2-1位置的元素, 即: 1,2 两个元素
    列表可以存在重复的元素

5. 列表进阶(096)
    多维列表: x = [[1,2,3],[4,5,6]] , 两行三列
    获取某个元素: x[0][1]
    快速创建列表: x = [12]*4 , 结果: [12,12,12,12]
    快速创建多维: x = [x]*3, 结果:[[12,12,12,12],[12,12,12,12],[12,12,12,12],[12,12,12,12]]

6. 字典(097)
    元组: x = (1,2,3)
    元组元素不能被修改: x[2] = 4 是错误的操作
    其它方面元组类似列表

    字典: x = {'a':1, 'b':3, 'c':4, 'd':5} 键值对的集合
    常用key做为索引: x['a']
    字典是无序的

    字典函数:
    x.get(key, 为空时返回的值) #如果返回结果为空时, 则返回指定的值
    x.setDefault(key, value)  #有则返回, 没有则添加此键值对
    x.keys()
    x.vlaues()
    x.items()
    字典的交集, 并集, 差集 同样要先转换为集合后操作

    所属判断: in, 判断一个元素是否属于一个列表, 元组, 字典

7. 集合(098)
    集合: {1,2,3,4}
    集合不允许存在重复项
    集合不能直接进行索引, 必先转换在列表后再进行索引操作
    集合取交集:
        a = [1,2,3]
        b = [2,3,4]
        set(a) & set(b) #取交集
        {2,3}
        set(a) | set(b) #取并集
        {1,2,3,4}
        set(a) - set(b) #取差集
        {1}

8. 控制流(099)
    a = 10
    if  a>5:
        打印条件为真时的结果
    else:
        打印条件为假时的结果

9. 控制循环流(100)
    count=0
    while count<10:
        print(count)
        count = count + 1

    循环中常用的break(终止循环), continue(跳过当次循环进入下次循环)
    pass 语句是个空语句, 语句占位符

    for i in range(10):
        print(i)

    for k,v in dict.items():
        print(k)
        print(v)

10. 循环进阶(101)
    python优雅的写法:
    [i for i in range(1,101) if i%2==0]
    等价于:
    list=[]
    for i in range(1,101):
        if i%2 == 0:
            list.append(i)

11. python函数(102)
    使用 def 定义函数
    def func(x):
        函数体语句集合

    定义函数
    def func(x):
        if(x>10):
            print('more than 10')
        else:
            print('less than 10')

    func(1)  #调用函数

    函数参数的默认值

12. 高阶函数(103)
    优雅函数: [i**2 for i in range(1,10)]
    还可以:
    def func(x):
        return x*x

    [frunc(i) for i in range(1,10)]

    map(func, 可变参数)
    map(func, [1,2,3,4,5])

    list(map(func, [1,2,3,4,5]))  #结果等价于 [frunc(i) for i in range(1,10)]

    a=[1,2,3,4,5]
    list(map(str, map(func, a))) #可嵌套使用

    匿名函数:
    lambda x:x*x
    list(map(lambda x:x*x, [1,2,3,4])) #免去定义函数的烦琐
    还可以嵌套一些系统内置函数, 比如 str , 转化为字符串类型
    list(map(lambda x:str(x), [1,2,3,4]))

13. 第三方包(104)
    import collections
        .Counter(list对象)  #用来计数统计, 以字典对象输出
    import csv #csv文件读写编辑
    import datetime #日期时间
    import math  #数学
    import pandas
    import numpy #数据分析相关的两个库

14. numpy(105)
    import numpy as np
    数组: a=np.array([1,2,3,4,5])
        可以将列表转化为数组
        a的数据类型 type(a) , numpy.ndarray 类型
        a+1 相当于数组的每个元素+1
        a*2
        a**2

        b=np.array([1,2,4],[2,3,4],[5,6,7],[7,8,9])
        b就是一个多维数组了, 也可以称为4*3的一个矩阵

        也可以通过b这个多维数组进行切片
        b[0]  结果就是 array([1,2,4])

        查看b数组中的数据类型: b.dtype()  , 结果: dtype('int32')
        而: type(1) 的数据类型是 int
        两种数据类型是区别的, 有时是需要转换的

        numpy 本身使用的就是数组结构

15. Pandas series (106) 索引列表
    import pandas as pd
    pandas 有两个数据结构 series(基础) 和 dataframe
    s=pd.Series([1,2,3,4])
    s的打印结果: 前者是索引,后者是数据元素
        0  1
        1  2
        2  3
        3  4
        dtype: int64
    s.index 可以打印出索引相关信息
        RangeIndex(start=0, stop=4, step=1)

    切片: s[1]  结果: 2

    s1=pd.Series([1,2,3,4], index=['a', 'b', 'c', 'd'])  结果索引被修改
        a  1
        b  2
        c  3
        d  4
        dtype: int64
    切片: s1['a']   结果: 1

    转换s1内元素的数据类型为 字符串
    s1.astype('str')  这样就转换成字符串对象
        a  1
        b  2
        c  3
        d  4
        dtype: object

    另一种转换数据类型的方式就是得用索引列表中类型必须是统一的,
    可以在s1对象中添加一个字符串元素: s1['A']='a'
    这样子的话, dtype: object 就自动转移为字符串对象

    多元素索引需要使用列表:
    s1[  ['a', 'c'] ] 结果:
        a  1
        c  3

    增加元素: 也可以修改元素
    s1['d'] = 5 , 这样s1对象中就增加了一个元素

    可以与字典互换
    d = {'a':'ok', 'b':'yes'}
    s2=pd.Series(d) 打印结果
        a  ok
        b  yes
        dtype: object

    强制为字典增加一个索引:
    s2 = pd.Series(d.index=['a', 'b', 'c'])  打印结果
        a  ok
        b  yes
        c  NaN
        dtype: object

16. Pandas dataframe (107)
    pd.DataFrame 是一个数据框
    而 pd.DataFrame([1,2,4,5])  生成的不是表格, 必须再执行一次
    pd.DataFrame(s) 将前的结果转换成表格形式
    但是如果pd.DataFrame([[1,2,3,4],[6,7,8,9]])  包含的是多维列表的话
    生成的就是一个表格了
    同样是使用index自定义行标签, column定义列标签, 两个参数都是列表

    x = pd.DataFrame({'a':[1,2,3,4],'b':[6,7,8,9]})
    x.info() 可获取表格的数据类型信息

    对DataFrame进行切片后, 会转换为 Series, 但是切多列的话仍是表格形式
    切片的方式可以 x['a'] 也可以是 x.a 的方式 (这是对列的切片)
    也可以对行进行切片 x.ix[0] 取0行

17. Python dataframe查找 (108)
    如: 查找age列中年龄==18的数据
    df[  df.age==18 ]  注意是两个等号, 在此基础上再切片 df[  df.age==18 ] .age
    也可 df[  ~df.age>19 ]  也可以对条件进行取反操作, 即查找 df.age<=18 的数据
    也可以多条件: df[  (df.age==18)&(df.name=='abc') ]

    另一种查询方式:
    df.query("(age==18) & (sex=='male')")

    df.iloc[1] 查询第1行数据, 是根据行编号查询
    df[1] 这种写法是错误的, df[0:1] 这样查询就是第0行数据
    df.iloc[行, 列], 如: df[1:2, 1:2] 这里是以数字进行切片的, 与行列标签名无关

    df.loc['a'] 查询 行标签为 a 的行数据, 即是根据行标签查询
    df.loc['a', 'age'] 行标签=a, 列标签=age 的交叉点数据
    df.loc['a', ['age', 'name']] 一行多列

    针对某列进行切片
    df.loc[  df.age==19, 'age' ] 查找或获取 age 列中 值是19的数据, 打印结果:
        a  19
        b  19
        Name: age, dtype: int64

    用上面方式查找的结果可以直接修改值: df.loc[  df.age==19, 'age' ] = 20

18. read_csv (109)
    import pandas as pd
    pd.read_csv('xxxxx.csv')  //前提是csv文件与脚本在同一目录下,默认是udf8解析
    pd.read_csv('xxxxx.csv', encoding='gbk') //原文件是GBK就需要添加这个参数, 但是分隔符是 '\t' , 所以需要指定分隔符
    pd.read_csv('xxxxx.csv', encoding='gbk', sep='\t', names=list('abcdefg'))  //names参数是可以指定列名的, 文档原有列名被定义为第0行数据.

    df = pd.read_csv('xxxxx.csv', encoding='gbk', sep='\t')
    df.info() //用于显示数据信息概览

    df.head() //只打印数据的前5行数据
    df.head(20) //则是打印前20行
    df.tail() //打印后5行数据
    df.tail(20) //打印后20行数据

    df.top.astype('str') //将top列的数据转换数据类型为字符串, 但这样子是不会改变原有数据类型的, 必须将这个改变后的类型赋值到表中对应的列才行
    df.top = df.top.astype('str')

    df[ (df.city == '上海') & (df.avg > 15) ] 多条件查询

19. 计算 (110)
    df.T   //这个是将原有表结构进行转置, 即行列数据互换
    df.sort_values(by='avg') //按avg列进行升序排序, 返回的仍然是数组结构
    df.avg.sort_values()   //只返回按升序排序后的 avg 列数组结果
    df.sort_values('avg') //同 by='avg' 的一样结果
    df.sort_values(['avg', 'city'], ascending=False)  //多列按降序排序

    df.sort_index()  //顾名知意, 就是按默认索引的升序排序

    排名 rank
    df.avg.rank() //根据avg的列值进行排名, 默认是升序
    df['rank'] = df.avg.rank() //为数组添加一列按avg排名的排名列值
    df['rank'] = df.avg.rank(ascending=false) //avg列排序按降序排名
    rank 生成排名时, 遇到相同值的数据, 默认是取相同avg值排名中的第一和最后一个的平均值, 所以有 +-0.5 浮动偏差.
    如: avg中是75的值有4个, 4个值的排序是1,2,3,4, 则取 (1+4)/2 = 2.5, 则4个avg=75 的值的排名就是2.5. 这是由 rank函数的method='average' 默认决定的, 当然这个参数是可以修改的.
    df['rank'] = df.avg.rank(ascending=false, method='min')  //同是按avg值第一次出现的排名算, 如: 75这个值第一次出现在排名中是 2, 则后面出的的75这个值都是2.
    df['rank'] = df.avg.rank(ascending=false, method='max')  //同min相反
    df['rank'] = df.avg.rank(ascending=false, method='first')  //不考虑并列的情况, 第几个出现的就是第几名
    df['rank'] = df.avg.rank(ascending=false, method='last')

    去重复 unique
    df.city.unique() //相当于SQL中的Distinct

    计数 value_counts
    df.city.value_counts()

    数据描述 describe()
    df.describe()
        count: 计数
        mean: 平均数
        std: 标准差
        min: 最小值
        25%, 50%, 75% 是分位数
        max: 最大值

    具体到每个字段的数据描述
    df.avg.describe()

    累加函数 cumsum
    df.avg.cumsum() //对avg列进行逐行累加

    分筒函数,bins, 此函数是与DataFrame同级的, 需要使用pd引用
    pd.cut(df.avg, bins=20) //即将avg字段中最小值到最大值进行20等分
    pd.cut(df.avg, bins=4, labels=list('abcd')) //labels参数是用分等级档次
    pd.cut(df.avg, bins=4, include_lowest=True) //include_lowest是否包含最小值
    pd.cut(df.avg, bins=[0, 5, 10, 20, 30, 100], labels=['0~5', '5~10', '10~20', '20~30', '30~100']) //手工分筒分级

20. Python groupby (111)
    df.groupby(by='city').count()  //按城市分组计数
    df.groupby(by='city').max() //按城市分组取每个分组的最大值
    df.groupby(by='city')['avg'].max() //按城市分组取每个分组中avg列的最大值
    df.groupby(by='city').avg.max()  //执行结果同上

    df.groupby(by=['city', 'workYear']).max() //按城市,工作年限进行分组聚合

    for k,v in df.groupby(by='city'):
        print(max(v.avg) - min(v['avg'])) //计算每个城市平均薪资最大值与最小值的差值
        print('**'*10) //打印10个 '**' 符号组成的分隔行

21. Python Pandas关联 (112)
    多表关联操作
    import pandas as pd
    position = pd.read_csv('position_gbk.csv', encoding='gbk')
    company = pd.read_csv('company_utf.csv', encoding='utf')

    三种关联方法: concat(类似SQL中的union), join(相当于SQL的join), merge(常用,默认等值连inner)
    position.merge(right=company, how='inner', left_on='companyId', right_on='id')
    两表联接, 右(right)表是company, 方式how是 inner, 等值条件, 左='companyId', 右='id'.

    也可以使用 pd 下面的merge函数
    pd.merge(左表, 右表, 联接方式, on条件, 右键, 右键, ... ...)

    join默认是基于表的索引进行关联
    company.join(position)

    concat 就是表的拼接或叫堆叠(简单粗暴)
    pd.concat(company, position) //默认是上下拼接
    pd.concat(['company', 'position'].axis=1) //更改为左右拼接
    常用于同结构多表合并操作

22. Python Pandas 多重索引(113)
    position.groupby(by=['city', 'education']).mean().avg['上海']
    position.groupby(by=['city', 'education']).mean()的结果是DataFrame类型,
    position.groupby(by=['city', 'education']).mean().avg 结果是Series类型一维
    所以可以直接单独取出 '上海' 的平均值数据

    position.groupby(by=['city', 'education']).mean().loc['上海']
    DataFrame类型的使用 loc 函数

    position.groupby(by=['city', 'education']).mean().loc['上海', '博士']

    另一种多重索引方式
    position.set_index(['city', 'education'])  //按城市和教育水平索引, 但数据零散
    position.sort_values(by=['city', 'education']).set_index(['city', 'education']) //先排序后的再进行索引, 数据就更加规整了.

    position.groupby(by=['city', 'education']).mean().reset_index()['avg']
    reset_index() 就是将分组列字段补全到每一行中去, 这样也可以根据字段名进行切片

23. Python Pandas 文本函数(114)
    position.positionLables.str //对position数组中的positionLables字段进行字符串处理函数str的使用.
   position.positionLables.str.count('分析师')  //统计每个字符串中 '分析师' 出现的次数
   position.positionLables.str.find('数据') //定位字符串出现的位置
   position.positionLables.str[1:-1] //对字符串进行切片

   DataFrame级别也有replace函数, 主要是对数组中的值进行处理
   position.positionLables.str[1:-1].replace("'","")  //此语句不可行, 切片后的数据是Series的一维数组, 还是需要先调用 str 函数, 变成position.positionLables.str[1:-1].str.replace("'","") 就可以了.

24. Python Pandas 去重(115)
    position.loc[position.city=='深圳', 'city'] //查询深圳城市数据, 只显示city列
    position.fillna(值) //用于填充DataFrame中字段值是 NaN 的字段
    position.city.fillna(值) //只对city列中的 NaN 值进行填充
    position.dropna() //删除存在NaN数据的行
        fillna和dropna函数中的 axis 是轴参数, 默认是0, 针对对象中的所有行, 如果axis=1, 则是针对列操作, 填充列中的NaN空值, 或是删除带有NaN空值的列

    position.duplicated()  //判断数据是否重复
    position[position.duplicated()] //筛选重复值

    实例: s = pd.Series([1,1,2,3,4])
    s.duplicated() //原理就是, 一个数据第一次出现时不是重复数据, 当同一个数据第二次出现是就会被判断为重复数据.
    s[s.duplicated()] //就可以筛选出重复行
    s[~s.duplicated()] //取反就是筛选出不重复的数据
    s.duplicated(keep='first') //判断第一个是非重复数据, 默认值
    s.duplicated(keep='last') //判断最后出现的数据为非重复数据
    s.drop_duplicates() //将去重后的数据返回

25. Python Pandas apply (116)
    position.avg.apply()  //apply函数的作用是将一个功能函数应用到每个值上
    position.avg.apply(lamda x:str(x)+'k') //使用一个匿名函数处理avg列中的每个值
    相当于,先定义一个函数func1
        def func1(x):
            if x>20: return '20+k'
            else: return '0~20k'

        position.avg.apply(func1)

    position对象直接调用, 就不能使用上面那个func1了, 需要进行 列指定
        def func2(x):
            if x.avg>20:
                return '20+k'
            else:
                return '0~20k'

        position.apply(func2, axis=1)  //逐行处理指定的avg列
        position.apply(lambda x:func1(x.avg), axis=1) //如何使用func1函数就这样

26. Python pandas 聚合 apply (117)
    筛选每个城市薪资水平前5的数据:
    def func(x):
        r = x.sort_values('avg', ascending=false)
        return  r[:5]

    position.groupby('city').apply(func)

    更多参数
    def func(x, n, asc=False):
        r = x.sort_values('avg', ascending=asc)
        return  r[:n]
    //查询每个城市, 薪资水平前3的, 排序是升序的数据
    position.groupby('city').apply(func, n=3, asc=True)

    另一个函数 agg
    position.groupby('city').agg(sum) //就可以按城市将数值数据字段进行求和
    position.groupby('city').agg('mean') //求平均
    position.groupby('city').mean() //与上面的求均是等价的

    position.groupby('city').agg(['sum', 'mean']) //也可以应用多个函数功能

    apply 与 agg 的区别是, 数据拆分, agg不能进行数据拆分, 只能生成一行数据
    但agg也是可以使用匿名函数:
    position.groupby('city').agg(lambda x:max(x)-min(x)) //返回的结果一个城市一行数据

27.  Python Pandas 数据透视(118)
    import pandas as pd
    import numpy as np
    position = pd.read_csv('position_gbk.csv', encoding='gbk')
    company = pd.read_csv('company_utf.csv', encoding='utf')

    数据透视函数pivot_table()
    position.pivot_table(index='city', columns='workYear', values='avg')
    参数:
        index: 行索引,
        columns: 列索引
        values: 值处理方式, 如平均值
        aggfun: 也是对数据的处理方法
        margins: 是否添加汇总行
    透视图表达的是, 每个城市, 按工作时长的年区间, 计算平均薪资

    多重索引
    position.pivot_table(index=['city', 'education'], columns='workYear', values='avg')
    每个城市中各学历, 在不同的工作年限区间中, 的平均薪资水平
    position.pivot_table(index=['city', 'education'], columns='workYear', values=['avg','top'], aggfun=[np.mean, np.sum]) //mean 是求平均值

    也可以进行切片
    position.pivot_table(index=['city', 'education'], columns='workYear', values=['top'], aggfun=[np.mean, np.sum])['mean']['avg'].loc['上海']

    添加汇总行
    position.pivot_table(index=['city', 'education'], columns='workYear', values=['top'], aggfun=[np.mean, np.sum], margins=True)

    针对特殊values进行指定方法处理
    position.pivot_table(index=['city', 'education'], columns='workYear', values=['top'], aggfun={'avg':np.mean, 'top':np.sum}) //通过字典的键值对指定

    透视表的输出, 输出为csv文件
    position.pivot_table(index=['city', 'education'], columns='workYear', values=['top'], aggfun={'avg':np.mean, 'top':np.sum}).reset_index().to_csv('text.csv') //reset_index() 函数是将结果集重置成二维表格

28. Python 连接数据库(119)
    安装数据库操作依赖包
    pip install pymysql
    如果存在Python多版本的问题, 可以使用
    pip3 install pymysql //这样就可以将这个依赖包安装在Python3的目录下

    import pymysql
    conn = pymysql.connect(
        host = 'localhost',
        user = 'root',
        password = '123456',
        db = 'data',
        port = 3306,
        charset = 'utf8'
    )
    cur = conn.cursor() //创建一个游标
    cur.execute('Select * from company') //执行一个SQL语句, 返回记录的行数
    data = cur.fetchall() //将查询的结果集合赋值给 data 变量

    conn.commit() //用于处理增, 删, 改, 查等语句

    注意: 使用过的游标和连接对象, 一定要记得关闭掉, 否则会有异常报错
    cur.close()
    conn.close()

    pandas 的数据库操作方式(新版本操作方式):
    import pandas as pd
    from sqlalchemy import create_engine
    或者
    import sqlalchemy  //ORM框架, 是一种新的数据库连接方式, 帮助用户进行数据读写

    sql = 'select * from company'
    engine = create_engine('mysql+pymysql://用户名:密码@服务器名或主机IP:端口号/数据库名?charset=utf8')  //这是一个固定的格式, 如 SuperSet 和 Hadoop平台搭建时使用的就这个格式.
    df = pd.read_sql(sql, engine) //旧版本中可以使用 Pymysql创建的连接对象conn, 但新版本里不行

29. Python 连接数据库2 (120)
    def reader(query, db):
        sql = query
        engine = create_engine('mysql+pymysql://root:123456@localhost:3306/{0}?charset={1}'.format(db)) //format(db, utf8) 中两个值会按{0}, {1}的顺序进行匹配
        df = pd.read_sql(sql, engine)
        return df

    reader('select * from company', 'data') //返回SQL语句查询的结果集, 一个二维表格
    reader('show tables', 'data') //返回data数据库中的表信息
    df_company = reader('select * from company', 'data')
    df_dataanalyst = reader('select * from dataanalyst', 'data')

    merged = pd.merge(df_dataanlyst, df_company, on='companyId') //合并两个表
    merged.head() //显示前5行数据
    merged.groupby(['city', 'companyFullName']).count() //按城市名和公司全称汇总, 计数处理操作
    result = merged.groupby(['city', 'companyFullName']).count()['positionId'].reset_index() //切片后重置为二维表格
    result.head()

    写入到数据库
    result.to_sql(
        name = '要定入的表名',
        con = 'mysql+pymysql://root:123456@127.0.0.1:3306/data?charset=utf8',
        if_exists = 'append', //如果是 fail, 则如果表已存在就写入失败, append 有则追加, 无则新建表
        index = False  //是否将默认的索引字段写入指定的表中
    )
    //针对写入数据库操作, 建议先根据要写入的数据手工建立表结构, 再写入数据, 因为自动创建的表, 其表结构或能不是我们想要的结果

30. Python 连接数据库3 (121)
    del  result['city']  //这个操作是删除result结果中的 city 列.

    写入到 CSV 文件中
    result.to_csv(
        name = 'CSV文件名.csv',
        con = 'mysql+pymysql://root:123456@127.0.0.1:3306/data?charset=utf8',
        if_exists = 'append', //如果是 fail, 则如果表已存在就写入失败, append 有则追加, 无则新建表
        index = False  //是否将默认的索引字段写入指定的表中
    )

31. Python 练习 Markdown (122)
    1. 了解一下Markdown的基本语法
    2. esc + m 转换为Markdown格式
    3. esc + c 切换到代码格式

32. Python 练习(一) (123)
    实例操作
    import pandas as pd
    import numpy as np
    columns = ['user_id', 'order_dt', 'order_products', order_amount'] //自定义表头
    df = pd.read_table('CDNOW_master.txt', names=columns, sep='\s+') //读入文本数据, 以若干空格分隔列
    df.info() 查看每个字段的数据类型信息等

    解析时间文本, 转换为时间格式
    df['order_dt'] = pd.to_datatime(df.order_dt, format="%Y%m%d")
    df['month'] = df.order_dt.values.astype('datetime64[M]')
    //datetime64[ns] 数据类型中的 ns 指的是转换精度, M就是精确到月份, Y精确到年份

33. Python 练习(二) (124)
    每月的消费总金额
    grouped_month = df.groupby('month')
    切片order_amount列并汇总
    order_month_amount = grouped_month.order_amount.sum()
    取默认前5行数据
    order_month_amount.head()

    加载数据可视化包
    import matplotlib.pyplot as plt
    可视化显示页面
    %matplotlib inline //jupyter内置专用命令, 主要作用就是数据可视化显示
    更改设计风格
    plt.style.use('ggplot')
    order_month_amount.plot()

    按月人数
    grouped_month.user_id.count().plot() //plot意思就是拆线图
    按月订单数
    grouped_month.order_products.sum().plot()
    去重复后每月消费人数
    df.groupby('month').user_id.apply(lambda x:len(x.drop_duplicates())).plot()

    数据透视
    df.pivot_tabe(index = 'month',
                        values = ['order_products', 'order_amount', 'user_id'],
                        aggfunc = {
                            'order_products':'sum',
                            'order_amount':'sum',
                            'user_id':'count'
                        }).head()

34. Python 练习(三) (125)
    上节是按月统计
    本节是个体消费分析
    grouped_user = df.groupby('user_id')
    grouped_user.sum().describe() //描述统计
    散点图显示
    grouped_user.sum().plot.scatter(x='order_amount', y='order_products')
    增加条件,去除极值的影响
    grouped_user.sum().query('order_amount<600').plot.scatter(x='order_amount', y='order_products')
    直方图
    grouped_user.sum().order_amount.plot.hist(bins=20)
    去除极值影响,增加查询条件
    grouped_user.sum().query('order_products<100').order_products.hist(bins=20)

    使用切比雪失定理过滤掉异常值, 计算95%的数据分布情况
    user_cumsum = grouped_user.sum().sort_values('order_amount').apply(lambda x:x.cumsum()/x.sum()) //cumsum() 滚动求和函数
    user_cumsum.reset_index().order_amount.plot()

35. Python 练习(四) (126)
    用户的消费行为
    grouped_user.min().order_dt.value_counts().plot()  //用户第一次消费分布
    grouped_user.max().order_dt.value_counts().plot() //用户最后一次消费分布
    user_life = grouped_user.order_dt.agg(['min', 'max']) //用户的第一次和最后一次消费的日期
    user_life.head() //打印前5行数据
    (user_life['min'] == user_life['max']).values.counts() //统计只消费一次和超过一次消费的用户数

    有一半用户消费一次
    rfm = df.pivot_table(
        index = 'user_id',
        values = ['order_products', 'order_amount', 'order_dt'],
        aggfunc = {
            'order_dt':'max',
            'order_amount':'sum',
            order_products':'sum'
        }
    )
    rfm.head()
    rfm['R'] = -(rfm.order_dt - rfm.order_dt.max()) / np.timedelta64(1,'D') //解析时间数据
    rfm.rename(columns={'order_products':'F', 'order_amount':'M'}, inplace = True) //修改列名
    rfm['R', 'F', 'M'].apply(lambda x:x-x.mean()) //与平均值的差

    对三列数据进行解析
    def  rfm_func(x):
        level = x.apply(lambda x:'1' if x>=1 else '0')
        label = level.R + level+F + level.M
        d = {
            '111':'重要价值客户',
            '011':'重要保持客户',
            '101':'重要发展客户',
            '001':'重要挽留客户',
            '110':'一般价值客户',
            '010':'一般保持客户',
            '100':'一般发展客户',
            '000':'一般挽留客户'
        }
        result = d[label]
        return result
    rfm['label'] = rfm[['R', 'F', 'M']]. apply(lambda x:x-mean()).apply(rfm_func, axis=1)

36. Python 练习(五) (127)
    rfm.groupby('label').sum() //按用户标签汇总数据

    rfm.loc[rfm.label=='重要价值客户','color'] = 'g'
    rfm.loc[~(rfm.label=='重要价值客户'),'color'] = 'r'
    rfm.plot.scatter('F', 'R', c=rfm.color)
    注意:
        1. 尽量用小部分的用户覆盖大部分的额度
        2. 不要为了数据好看划分等级

37. Python 练习(六) (128)
    pivoted_counts = df.pivot_table(
        index = 'user_id',
        columns = 'month',
        values = order_dt',
        aggfunc = 'count'
    ).fillna(0)
    pivoted_counts.head()

    df_purchase = pivoted_counts.applymap(lambda x:1 if x>0 else 0)
    df_purchase.tail()

    def active_status(data):
        status = []
        for i in range(18):
            //若本月没有消费
            if data[i] == 0:
                if len(status) > 0:
                    if status[i-1] == 'unreg':
                        status.append('unreg')
                    else:
                        status.append('unactive')
                else:
                    status.append('unreg')
            //若本月有消费
            else:
                if len(status) == 0:
                    status.append('new')
                else:
                    if status[i-1] == 'unactive':
                        status.append('return')
                    elif status[i-1] == 'unreg':
                        status.append('new')
                    else:
                        status.append('active')
    return status
    purchase_stats = df_purchase.apply(active_status, axis=1)
    purchase_stats.head()

    purchase_stats_ct = purchase_stats.replace('unreg', np.NaN).apply(lambda x:pd.value_counts(x))
    purchase_stats_ct.fillna(0).T //T的作用是转置
    purchase_stats_ct.fillna(0).T.plot.area() //面积图

38. Python 练习(七) (129)
    purchase_stats_ct.fillna(0).T.apply(lambda x:x/x.sum(), axis = 1)

    //计算每个用户的购买周期
    order_diff = grouped_user.apply(lambda x:x.order_dt - x.order_dt.shift()) //shift() 偏移函数
    order_diff.head(10)
    order_diff.decribe() //用户购买数据描述

    (order_diff / np.timedelta64(1,'D')).hist(bins=20) //直方图

    (user_life['max'] - user_life['min']).describe() //用户最大活跃周期内的数据描述
    ((user_life['max'] - user_life['min']) / np.timedelta64(1,'D')).hist(bins=40)

    u_l =((user_life['max'] - user_life['min']).reset_index()[0] / np.timedelta64(1,'D'))
    u_l[u_l>0].hist(bins=40)

39. Python 练习(八) (130)
    回购率和复购率
    pivoted_counts.head()
    purchase_r = pivoted_counts.applymap(lambda x: 1 if x>1 else np.NaN if x==0 else 0)
    purchase_r.head()
    (purchase_r.sum() / purchase_r.count()).plot(figsize = (10,4)) //figszie参数是设置图的宽高
    df_purchase.head()

    def purchase_back(data):
        status = []
        for i in range(17):
            if data[i] == 1:
                if data[i+1] == 1:
                    status.append(1)
                if data[i+1] == 0:
                    status.append(0)
            else:
                status.append(np.NaN)
        status.append(np.NaN)
        return status

    purchase_b = df_purchase.apply(purchase_back, axis=1)
    purchase_b.head()
    (purchase_b.sum() / purchase_b.count()).plot(figsize = (10,4))

40. Python 练习(九) (131)
    更换新的SQL语句,套用以上使用的命令模板

41. Python 可视化(一) (132)
    拆线图 plot
    柱形图 bar
    直方图 hist
    箱线图 box
    密度图 kde
    面积图 area
    散点图 scatter
    散点图矩阵 scatter_matrix
    饼图 pie

    import pandas as pd
    df = pd.read_csv('position_gbk.csv', encoding='gbk')
    %matplotlib inline  //jupyter内置命令, 用于Python可视化显示图像

    df.avg.plot() //拆线图显示平均薪资
    df.avg.value_counts().sort_index().plot()
    df.avg.value_counts().sort_index().plot(kind='bar')
    df.avg.value_counts().sort_index().plot.bar()
    //默认不支持中文显示, 见后面有关的解决方法
    df_plot_bar = df.pivot_table(index='city', columns='education', values='avg', aggfunc='count')
    df_plot_bar.plot.bar() //普通柱形图
    df_plot_bar.plot.bar(stacked=True) //堆积柱形图
    df_plot_bar.plot.barh(stacked=True) //堆积柱形图, 水平显示

42. Python 可视化(二) (133)
    df.avg.hist() //可以直接调用, 显示网格
    df.avg.plot.hist() //建议这样搞, 去除网格, 相比上面的写法, 参数少了, 常用 bins参数设置箱体的个数

    //unstack() 是反堆叠函数, T 是行列转置, alpha 设置透明度
    df_plot_hist = df.groupby('education').apply(lambda x:x.avg).unstack().T
    df_plot_hist.plot.hist(alpha=0.5)
    df_plot_hist.plot.hist(alpha=0.5, stacked=True, bins=30)

43. Python 可视化(三) (134)
    df_plot_box = df.groupby('education').apply(lambda x:x.avg).unstack().T
    df_plot_box.plot.box()

    另一种箱线图画法
    df.boxplot(column='avg', by='education') //column是列值, by是X轴索引, 跟上一种结果相同

    密度图
    df.avg.plot.kde()

44. Python 可视化(四) (135)
    df_plot_area = df.pivot_table(index='avg', columns='education', aggfunc='count', values='positionId')
    df_plot_area.plot.area() //面积图

    散点图
    df_plot_scatter = df.groupby('companyId').aggregrate(['mean', 'count', 'max']).avg
    df_plot_scatter.plot.scatter(x='mean', y='count') //散点图

    散点图矩阵 //不在plot下的一个绘图函数
    pd.plotting.scatter_matrix(df_plot_scatter, query('count<50'), diagonal='kde')

    饼图
    df.city.value_counts().plot.pie(figsize=(6,6)) //宽高相等的圆形饼图

45. Python 可视化(五) (136)
    解决中文显示的问题, 添加更多绘图元素
    import numpy as np
    import matplotlib.pyplot as plt
    plt.rcParams['font.sans-serif'] = ['SimHei'] //设置字体为黑体
    plt.rcParams['axes.unicode_minus'] = False  //使坐标轴能够显示负数, True不显示, False显示

    //熟悉一下plt的绘图功能
    df_data = df.groupby('city').avg.count()
    plt.pie(df_data, labels=df_data.index) //带有标签的饼图

    //关于坐标轴上显示负数的示例
    np_data = np.random.random_integers(-20, 20, 20) //随机从 -20 到 20 的区间中获取 20个数字
    plt.plot(np_data)

46. Python 可视化(六) (137)
    主要的绘图元素
    figure : 这里是画布的意思
    元素:
        title 标题
        data 数据
        X 轴
            X轴刻度, xtick
            X标签, xlabel
        Y 轴
            Y轴刻度, ytick
            Y标签, ylabel

    plt.figure(1, figsize=(10,4)) //定义画布中只显示一个绘图, 图像宽高使用一个元组定义(10,4)
    plt.plot(np_data)
    plt.plot(np_data) //这里使用两次随机数据, 在画布上就可以显示两条拆线
    plt.title('这是一条拆线图') //python3的写法, 为图像添加一个标题, 乱码的话字符串前加 R
    plt.xticks([0, 20, 40, 60]) //自定义X轴的刻度
    plt.xlabel('X轴标题') //定义 X 轴的标题
    plt.legend(('data1', 'data2')) //legend() 函数接收一个元组来创建一个图例, 两条拆线自动匹配
    plt.show() //不显示图像的内存地址

47. Python 可视化(七) (138)
    plt.figure(1, figsize=(10,4)) //定义画布中只显示一个绘图, 图像宽高使用一个元组定义(10,4)
    plt.plot(np_data, label='data1', color='r')  //color参数是修改图例的颜色
    plt.plot(np_data, label='data2') //这里使用两次随机数据, 在画布上就可以显示两条拆线
    plt.title('这是一条拆线图') //python3的写法, 为图像添加一个标题, 乱码的话字符串前加 R
    plt.xticks([0, 20, 40, 60]) //自定义X轴的刻度
    plt.xlabel('X轴标题') //定义 X 轴的标题
    plt.legend() //如果拆线中使用了label参数, 这里就为空,只作用于是否显示图例
    plt.show() //不显示图像的内存地址

    练习
    df_data = df.groupby(['education', 'companyId']).aggregrate(['mean', 'count']).avg.reset_index()

    for edu, grouped in df_data.groupby('education'):
        x = grouped['mean']
        y = grouped['count']
        plt.scatter(x, y, label=edu)
    plt.legend(loc='upper right')  //loc参数是用来定位图例在画布中的位置
    plt.show()

48. Python 可视化(八) (139)
    绘制子图
    import pandas as pd
    import numpy as np
    import matplotlib.pyplot as plt
    plt.rcParams['font.sans-serif'] = ['SimHei'] //设置字体为黑体
    plt.rcParams['axes.unicode_minus'] = False  //使坐标轴能够显示负数, True不显示, False显示

    np_data = np.random.random_integers(-20, 20, 20)

    plt.figure(figsize=(12,6)) //首先定义画布的尺寸

    //绘制第一张图
    plt.subplot(1,2,1) //切分画布为1行2列, 定位第1行1列, 也可缩写为 plt.subplot(121)
    plt.plot(np_data, label='data1', color='r')  //color参数是修改图例的颜色
    plt.plot(np_data, label='data2', color='g')
    plt.legend() //显示图例

    //绘制第二张图
    plt.subplot(1,2,2) //定位第1行2列
    plt.plot(np_data, label='data3') //这里使用两次随机数据, 在画布上就可以显示两条拆线
    plt.plot(np_data, label='data4')
    plt.legend()

    //最后统一显示
    plt.show()

    //绘制不规则图表, 如, 上面显示两个, 下面显示一个, 跨两列
    plt.figure(figsize=(12,8))
    plt.subplot(221) //2行2列的第一个位置
    画图1
    plt.subplot(222) //2行2列的第二个位置
    画图2
    plt.subplot(212) //2行1列的第三个位置
    跨上面两列画图3

    注意: subplot() 前两个参数每次都声明行列数, 用于画布切份, 最后一个是所占位置.
    //同理绘制左边上下各一个, 右边跨两行
    plt.subplot(2,2,1)
    plt.subplot(2,2,3)
    plt.subplot(1,2,2)














